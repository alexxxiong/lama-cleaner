"""
åˆ†å¸ƒå¼ç³»ç»Ÿä¸“ç”¨æ—¥å¿—å™¨

ä¸ºåˆ†å¸ƒå¼ç³»ç»Ÿçš„å„ä¸ªæ¨¡å—æä¾›ä¸“é—¨çš„æ—¥å¿—è®°å½•åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- è°ƒåº¦å™¨æ—¥å¿—
- å·¥ä½œèŠ‚ç‚¹æ—¥å¿—  
- ä»»åŠ¡ç®¡ç†å™¨æ—¥å¿—
- é˜Ÿåˆ—ç®¡ç†å™¨æ—¥å¿—
"""

import json
import time
from typing import Dict, Any, Optional, List
from datetime import datetime
from loguru import logger
from .models import Task, TaskStatus, NodeStatus, NodeCapability


class DistributedLogger:
    """åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€æ—¥å¿—å™¨"""
    
    def __init__(self, module_name: str):
        self.module_name = module_name
        self.logger = logger.bind(name=f"distributed.{module_name}")
        
    def _log_with_context(self, level: str, message: str, **context):
        """å¸¦ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ—¥å¿—è®°å½•"""
        extra_data = {
            "module": self.module_name,
            "timestamp": datetime.now().isoformat(),
            **context
        }
        
        # æ ¹æ®çº§åˆ«è°ƒç”¨å¯¹åº”çš„æ—¥å¿—æ–¹æ³•
        log_method = getattr(self.logger, level.lower())
        log_method(message, extra=extra_data)
    
    def info(self, message: str, **context):
        """ä¿¡æ¯æ—¥å¿—"""
        self._log_with_context("INFO", message, **context)
    
    def success(self, message: str, **context):
        """æˆåŠŸæ—¥å¿—"""
        self._log_with_context("SUCCESS", message, **context)
    
    def warning(self, message: str, **context):
        """è­¦å‘Šæ—¥å¿—"""
        self._log_with_context("WARNING", message, **context)
    
    def error(self, message: str, **context):
        """é”™è¯¯æ—¥å¿—"""
        self._log_with_context("ERROR", message, **context)
    
    def debug(self, message: str, **context):
        """è°ƒè¯•æ—¥å¿—"""
        self._log_with_context("DEBUG", message, **context)


class SchedulerLogger(DistributedLogger):
    """è°ƒåº¦å™¨ä¸“ç”¨æ—¥å¿—å™¨"""
    
    def __init__(self):
        super().__init__("scheduler")
    
    def log_startup(self, config: Dict[str, Any]):
        """è®°å½•è°ƒåº¦å™¨å¯åŠ¨"""
        self.info("ğŸš€ è°ƒåº¦å™¨å¯åŠ¨å¼€å§‹", 
                 action="startup_begin",
                 config=config)
    
    def log_startup_complete(self, host: str, port: int, startup_time: float):
        """è®°å½•è°ƒåº¦å™¨å¯åŠ¨å®Œæˆ"""
        self.success(f"âœ… è°ƒåº¦å™¨å¯åŠ¨å®Œæˆ - {host}:{port} (è€—æ—¶: {startup_time:.2f}s)",
                    action="startup_complete",
                    host=host,
                    port=port,
                    startup_time=startup_time)
    
    def log_task_received(self, task: Task):
        """è®°å½•æ¥æ”¶åˆ°æ–°ä»»åŠ¡"""
        self.info(f"ğŸ“‹ æ¥æ”¶æ–°ä»»åŠ¡: {task.task_id}",
                 action="task_received",
                 task_id=task.task_id,
                 task_type=task.task_type.value,
                 priority=task.priority.value,
                 user_id=task.user_id)
    
    def log_task_routed(self, task_id: str, node_id: str, routing_reason: str):
        """è®°å½•ä»»åŠ¡è·¯ç”±"""
        self.info(f"ğŸ¯ ä»»åŠ¡è·¯ç”±: {task_id} -> {node_id}",
                 action="task_routed",
                 task_id=task_id,
                 target_node=node_id,
                 routing_reason=routing_reason)
    
    def log_node_registered(self, node_id: str, capability: NodeCapability):
        """è®°å½•èŠ‚ç‚¹æ³¨å†Œ"""
        self.success(f"ğŸ”— èŠ‚ç‚¹æ³¨å†ŒæˆåŠŸ: {node_id}",
                    action="node_registered",
                    node_id=node_id,
                    node_type=capability.node_type.value,
                    gpu_available=capability.gpu_available,
                    memory_gb=capability.memory_gb)
    
    def log_node_disconnected(self, node_id: str, reason: str):
        """è®°å½•èŠ‚ç‚¹æ–­å¼€è¿æ¥"""
        self.warning(f"ğŸ”Œ èŠ‚ç‚¹æ–­å¼€è¿æ¥: {node_id}",
                    action="node_disconnected",
                    node_id=node_id,
                    reason=reason)
    
    def log_queue_stats(self, queue_name: str, pending: int, processing: int):
        """è®°å½•é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        self.debug(f"ğŸ“Š é˜Ÿåˆ—çŠ¶æ€: {queue_name} (å¾…å¤„ç†: {pending}, å¤„ç†ä¸­: {processing})",
                  action="queue_stats",
                  queue_name=queue_name,
                  pending_count=pending,
                  processing_count=processing)
    
    def log_error(self, error_msg: str, error_type: str, **context):
        """è®°å½•è°ƒåº¦å™¨é”™è¯¯"""
        self.error(f"âŒ è°ƒåº¦å™¨é”™è¯¯: {error_msg}",
                  action="scheduler_error",
                  error_type=error_type,
                  **context)


class WorkerLogger(DistributedLogger):
    """å·¥ä½œèŠ‚ç‚¹ä¸“ç”¨æ—¥å¿—å™¨"""
    
    def __init__(self, node_id: str):
        super().__init__("worker")
        self.node_id = node_id
    
    def log_startup(self, capability: NodeCapability):
        """è®°å½•å·¥ä½œèŠ‚ç‚¹å¯åŠ¨"""
        self.info(f"ğŸš€ å·¥ä½œèŠ‚ç‚¹å¯åŠ¨: {self.node_id}",
                 action="worker_startup",
                 node_id=self.node_id,
                 node_type=capability.node_type.value,
                 gpu_available=capability.gpu_available,
                 memory_gb=capability.memory_gb,
                 cpu_cores=capability.cpu_cores)
    
    def log_registration_attempt(self, scheduler_host: str, scheduler_port: int):
        """è®°å½•æ³¨å†Œå°è¯•"""
        self.info(f"ğŸ”— å°è¯•æ³¨å†Œåˆ°è°ƒåº¦å™¨: {scheduler_host}:{scheduler_port}",
                 action="registration_attempt",
                 node_id=self.node_id,
                 scheduler_host=scheduler_host,
                 scheduler_port=scheduler_port)
    
    def log_registration_success(self):
        """è®°å½•æ³¨å†ŒæˆåŠŸ"""
        self.success(f"âœ… èŠ‚ç‚¹æ³¨å†ŒæˆåŠŸ: {self.node_id}",
                    action="registration_success",
                    node_id=self.node_id)
    
    def log_registration_failed(self, error: str):
        """è®°å½•æ³¨å†Œå¤±è´¥"""
        self.error(f"âŒ èŠ‚ç‚¹æ³¨å†Œå¤±è´¥: {self.node_id}",
                  action="registration_failed",
                  node_id=self.node_id,
                  error=error)
    
    def log_task_received(self, task: Task):
        """è®°å½•æ¥æ”¶åˆ°ä»»åŠ¡"""
        self.info(f"ğŸ“‹ æ¥æ”¶ä»»åŠ¡: {task.task_id}",
                 action="task_received",
                 node_id=self.node_id,
                 task_id=task.task_id,
                 task_type=task.task_type.value)
    
    def log_task_processing_start(self, task_id: str):
        """è®°å½•ä»»åŠ¡å¼€å§‹å¤„ç†"""
        self.info(f"âš¡ å¼€å§‹å¤„ç†ä»»åŠ¡: {task_id}",
                 action="task_processing_start",
                 node_id=self.node_id,
                 task_id=task_id,
                 start_time=datetime.now().isoformat())
    
    def log_task_processing_complete(self, task_id: str, processing_time: float):
        """è®°å½•ä»»åŠ¡å¤„ç†å®Œæˆ"""
        self.success(f"âœ… ä»»åŠ¡å¤„ç†å®Œæˆ: {task_id} (è€—æ—¶: {processing_time:.2f}s)",
                    action="task_processing_complete",
                    node_id=self.node_id,
                    task_id=task_id,
                    processing_time=processing_time)
    
    def log_task_processing_failed(self, task_id: str, error: str):
        """è®°å½•ä»»åŠ¡å¤„ç†å¤±è´¥"""
        self.error(f"âŒ ä»»åŠ¡å¤„ç†å¤±è´¥: {task_id}",
                  action="task_processing_failed",
                  node_id=self.node_id,
                  task_id=task_id,
                  error=error)
    
    def log_heartbeat_sent(self, status: NodeStatus):
        """è®°å½•å¿ƒè·³å‘é€"""
        self.debug(f"ğŸ’“ å‘é€å¿ƒè·³: {self.node_id}",
                  action="heartbeat_sent",
                  node_id=self.node_id,
                  status=status.value)
    
    def log_capability_update(self, new_capability: NodeCapability):
        """è®°å½•èƒ½åŠ›æ›´æ–°"""
        self.info(f"ğŸ”„ èŠ‚ç‚¹èƒ½åŠ›æ›´æ–°: {self.node_id}",
                 action="capability_update",
                 node_id=self.node_id,
                 gpu_available=new_capability.gpu_available,
                 memory_gb=new_capability.memory_gb)


class TaskManagerLogger(DistributedLogger):
    """ä»»åŠ¡ç®¡ç†å™¨ä¸“ç”¨æ—¥å¿—å™¨"""
    
    def __init__(self):
        super().__init__("task_manager")
    
    def log_task_created(self, task: Task):
        """è®°å½•ä»»åŠ¡åˆ›å»º"""
        self.info(f"ğŸ“ ä»»åŠ¡åˆ›å»º: {task.task_id}",
                 action="task_created",
                 task_id=task.task_id,
                 task_type=task.task_type.value,
                 priority=task.priority.value,
                 user_id=task.user_id,
                 created_at=task.created_at.isoformat())
    
    def log_task_status_change(self, task_id: str, old_status: TaskStatus, new_status: TaskStatus):
        """è®°å½•ä»»åŠ¡çŠ¶æ€å˜æ›´"""
        self.info(f"ğŸ”„ ä»»åŠ¡çŠ¶æ€å˜æ›´: {task_id} ({old_status.value} -> {new_status.value})",
                 action="task_status_change",
                 task_id=task_id,
                 old_status=old_status.value,
                 new_status=new_status.value,
                 change_time=datetime.now().isoformat())
    
    def log_task_lifecycle_event(self, task_id: str, event: str, **context):
        """è®°å½•ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸäº‹ä»¶"""
        self.info(f"ğŸ“Š ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸ: {task_id} - {event}",
                 action="task_lifecycle_event",
                 task_id=task_id,
                 event=event,
                 **context)
    
    def log_task_timeout(self, task_id: str, timeout_duration: float):
        """è®°å½•ä»»åŠ¡è¶…æ—¶"""
        self.warning(f"â° ä»»åŠ¡è¶…æ—¶: {task_id} (è¶…æ—¶æ—¶é—´: {timeout_duration}s)",
                    action="task_timeout",
                    task_id=task_id,
                    timeout_duration=timeout_duration)
    
    def log_task_retry(self, task_id: str, retry_count: int, max_retries: int):
        """è®°å½•ä»»åŠ¡é‡è¯•"""
        self.info(f"ğŸ”„ ä»»åŠ¡é‡è¯•: {task_id} (ç¬¬{retry_count}/{max_retries}æ¬¡)",
                 action="task_retry",
                 task_id=task_id,
                 retry_count=retry_count,
                 max_retries=max_retries)
    
    def log_batch_operation(self, operation: str, task_count: int, **context):
        """è®°å½•æ‰¹é‡æ“ä½œ"""
        self.info(f"ğŸ“¦ æ‰¹é‡æ“ä½œ: {operation} ({task_count}ä¸ªä»»åŠ¡)",
                 action="batch_operation",
                 operation=operation,
                 task_count=task_count,
                 **context)


class QueueManagerLogger(DistributedLogger):
    """é˜Ÿåˆ—ç®¡ç†å™¨ä¸“ç”¨æ—¥å¿—å™¨"""
    
    def __init__(self):
        super().__init__("queue_manager")
    
    def log_queue_created(self, queue_name: str, config: Dict[str, Any]):
        """è®°å½•é˜Ÿåˆ—åˆ›å»º"""
        self.info(f"ğŸ“‹ é˜Ÿåˆ—åˆ›å»º: {queue_name}",
                 action="queue_created",
                 queue_name=queue_name,
                 config=config)
    
    def log_message_sent(self, queue_name: str, message_type: str, message_id: str):
        """è®°å½•æ¶ˆæ¯å‘é€"""
        self.debug(f"ğŸ“¤ æ¶ˆæ¯å‘é€: {queue_name} - {message_type}",
                  action="message_sent",
                  queue_name=queue_name,
                  message_type=message_type,
                  message_id=message_id)
    
    def log_message_received(self, queue_name: str, message_type: str, message_id: str):
        """è®°å½•æ¶ˆæ¯æ¥æ”¶"""
        self.debug(f"ğŸ“¥ æ¶ˆæ¯æ¥æ”¶: {queue_name} - {message_type}",
                  action="message_received",
                  queue_name=queue_name,
                  message_type=message_type,
                  message_id=message_id)
    
    def log_queue_stats(self, queue_name: str, stats: Dict[str, int]):
        """è®°å½•é˜Ÿåˆ—ç»Ÿè®¡"""
        self.debug(f"ğŸ“Š é˜Ÿåˆ—ç»Ÿè®¡: {queue_name}",
                  action="queue_stats",
                  queue_name=queue_name,
                  **stats)
    
    def log_connection_error(self, queue_name: str, error: str):
        """è®°å½•è¿æ¥é”™è¯¯"""
        self.error(f"âŒ é˜Ÿåˆ—è¿æ¥é”™è¯¯: {queue_name}",
                  action="connection_error",
                  queue_name=queue_name,
                  error=error)
    
    def log_queue_overflow(self, queue_name: str, current_size: int, max_size: int):
        """è®°å½•é˜Ÿåˆ—æº¢å‡º"""
        self.warning(f"âš ï¸ é˜Ÿåˆ—æº¢å‡º: {queue_name} ({current_size}/{max_size})",
                    action="queue_overflow",
                    queue_name=queue_name,
                    current_size=current_size,
                    max_size=max_size)


class ModelManagerLogger(DistributedLogger):
    """AIæ¨¡å‹ç®¡ç†å™¨ä¸“ç”¨æ—¥å¿—å™¨"""
    
    def __init__(self):
        super().__init__("model_manager")
    
    def log_model_loading_start(self, model_name: str, device: str, **context):
        """è®°å½•æ¨¡å‹åŠ è½½å¼€å§‹"""
        self.info(f"ğŸ¤– å¼€å§‹åŠ è½½æ¨¡å‹: {model_name} (è®¾å¤‡: {device})",
                 action="model_loading_start",
                 model_name=model_name,
                 device=device,
                 **context)
    
    def log_model_loading_complete(self, model_name: str, loading_time: float, 
                                  memory_usage: Optional[Dict[str, float]] = None, **context):
        """è®°å½•æ¨¡å‹åŠ è½½å®Œæˆ"""
        self.success(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ: {model_name} ({loading_time:.2f}s)",
                    action="model_loading_complete",
                    model_name=model_name,
                    loading_time=loading_time,
                    memory_usage=memory_usage or {},
                    **context)
    
    def log_model_loading_failed(self, model_name: str, error: str, **context):
        """è®°å½•æ¨¡å‹åŠ è½½å¤±è´¥"""
        self.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {model_name}",
                  action="model_loading_failed",
                  model_name=model_name,
                  error=error,
                  **context)
    
    def log_model_switch_start(self, old_model: str, new_model: str, **context):
        """è®°å½•æ¨¡å‹åˆ‡æ¢å¼€å§‹"""
        self.info(f"ğŸ”„ å¼€å§‹åˆ‡æ¢æ¨¡å‹: {old_model} -> {new_model}",
                 action="model_switch_start",
                 old_model=old_model,
                 new_model=new_model,
                 **context)
    
    def log_model_switch_complete(self, old_model: str, new_model: str, 
                                 switch_time: float, **context):
        """è®°å½•æ¨¡å‹åˆ‡æ¢å®Œæˆ"""
        self.success(f"âœ… æ¨¡å‹åˆ‡æ¢å®Œæˆ: {old_model} -> {new_model} ({switch_time:.2f}s)",
                    action="model_switch_complete",
                    old_model=old_model,
                    new_model=new_model,
                    switch_time=switch_time,
                    **context)
    
    def log_model_inference_start(self, model_name: str, input_shape: tuple, **context):
        """è®°å½•æ¨¡å‹æ¨ç†å¼€å§‹"""
        self.debug(f"ğŸ§  å¼€å§‹æ¨¡å‹æ¨ç†: {model_name} (è¾“å…¥: {input_shape})",
                  action="model_inference_start",
                  model_name=model_name,
                  input_shape=input_shape,
                  **context)
    
    def log_model_inference_complete(self, model_name: str, inference_time: float, 
                                   output_shape: tuple, **context):
        """è®°å½•æ¨¡å‹æ¨ç†å®Œæˆ"""
        self.debug(f"âœ… æ¨¡å‹æ¨ç†å®Œæˆ: {model_name} ({inference_time:.3f}s, è¾“å‡º: {output_shape})",
                  action="model_inference_complete",
                  model_name=model_name,
                  inference_time=inference_time,
                  output_shape=output_shape,
                  **context)
    
    def log_gpu_memory_usage(self, model_name: str, memory_info: Dict[str, float]):
        """è®°å½•GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
        allocated = memory_info.get('allocated', 0) / 1024**3  # GB
        cached = memory_info.get('cached', 0) / 1024**3  # GB
        total = memory_info.get('total', 0) / 1024**3  # GB
        
        self.debug(f"ğŸ’¾ GPUå†…å­˜ä½¿ç”¨: {model_name} (å·²åˆ†é…: {allocated:.1f}GB, ç¼“å­˜: {cached:.1f}GB, æ€»è®¡: {total:.1f}GB)",
                  action="gpu_memory_usage",
                  model_name=model_name,
                  memory_allocated_gb=allocated,
                  memory_cached_gb=cached,
                  memory_total_gb=total)
    
    def log_memory_cleanup(self, model_name: str, freed_memory: float):
        """è®°å½•å†…å­˜æ¸…ç†"""
        self.info(f"ğŸ§¹ å†…å­˜æ¸…ç†: {model_name} (é‡Šæ”¾: {freed_memory / 1024**3:.1f}GB)",
                 action="memory_cleanup",
                 model_name=model_name,
                 freed_memory_gb=freed_memory / 1024**3)
    
    def log_model_download_start(self, model_name: str, download_url: str):
        """è®°å½•æ¨¡å‹ä¸‹è½½å¼€å§‹"""
        self.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}",
                 action="model_download_start",
                 model_name=model_name,
                 download_url=download_url)
    
    def log_model_download_progress(self, model_name: str, progress: float, 
                                   downloaded_mb: float, total_mb: float):
        """è®°å½•æ¨¡å‹ä¸‹è½½è¿›åº¦"""
        self.debug(f"ğŸ“Š ä¸‹è½½è¿›åº¦: {model_name} ({progress:.1%}, {downloaded_mb:.1f}/{total_mb:.1f}MB)",
                  action="model_download_progress",
                  model_name=model_name,
                  progress=progress,
                  downloaded_mb=downloaded_mb,
                  total_mb=total_mb)
    
    def log_model_download_complete(self, model_name: str, download_time: float, 
                                   file_size_mb: float):
        """è®°å½•æ¨¡å‹ä¸‹è½½å®Œæˆ"""
        self.success(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_name} ({download_time:.1f}s, {file_size_mb:.1f}MB)",
                    action="model_download_complete",
                    model_name=model_name,
                    download_time=download_time,
                    file_size_mb=file_size_mb)
    
    def log_controlnet_switch(self, old_method: str, new_method: str):
        """è®°å½•ControlNetæ–¹æ³•åˆ‡æ¢"""
        self.info(f"ğŸ›ï¸ ControlNetæ–¹æ³•åˆ‡æ¢: {old_method} -> {new_method}",
                 action="controlnet_switch",
                 old_method=old_method,
                 new_method=new_method)


class APIServerLogger(DistributedLogger):
    """APIæœåŠ¡å™¨ä¸“ç”¨æ—¥å¿—å™¨"""
    
    def __init__(self):
        super().__init__("api_server")
    
    def log_request_start(self, method: str, path: str, user_id: Optional[str] = None, 
                         session_id: Optional[str] = None, **context):
        """è®°å½•APIè¯·æ±‚å¼€å§‹"""
        self.info(f"ğŸ“¥ {method} {path}",
                 action="request_start",
                 method=method,
                 path=path,
                 user_id=user_id,
                 session_id=session_id,
                 **context)
    
    def log_request_complete(self, method: str, path: str, status_code: int, 
                           response_time: float, **context):
        """è®°å½•APIè¯·æ±‚å®Œæˆ"""
        status_emoji = "âœ…" if status_code < 400 else "âŒ"
        self.info(f"{status_emoji} {method} {path} -> {status_code} ({response_time:.3f}s)",
                 action="request_complete",
                 method=method,
                 path=path,
                 status_code=status_code,
                 response_time=response_time,
                 **context)
    
    def log_file_upload(self, filename: str, file_size: int, file_type: str, **context):
        """è®°å½•æ–‡ä»¶ä¸Šä¼ """
        self.info(f"ğŸ“¤ æ–‡ä»¶ä¸Šä¼ : {filename} ({file_size} bytes)",
                 action="file_upload",
                 filename=filename,
                 file_size=file_size,
                 file_type=file_type,
                 **context)
    
    def log_image_processing_start(self, task_id: str, image_path: str, 
                                  processing_type: str, **context):
        """è®°å½•å›¾åƒå¤„ç†å¼€å§‹"""
        self.info(f"ğŸ–¼ï¸ å¼€å§‹å›¾åƒå¤„ç†: {task_id} - {processing_type}",
                 action="image_processing_start",
                 task_id=task_id,
                 image_path=image_path,
                 processing_type=processing_type,
                 **context)
    
    def log_image_processing_complete(self, task_id: str, processing_time: float, 
                                    output_path: str, **context):
        """è®°å½•å›¾åƒå¤„ç†å®Œæˆ"""
        self.success(f"âœ… å›¾åƒå¤„ç†å®Œæˆ: {task_id} ({processing_time:.2f}s)",
                    action="image_processing_complete",
                    task_id=task_id,
                    processing_time=processing_time,
                    output_path=output_path,
                    **context)
    
    def log_image_processing_failed(self, task_id: str, error: str, **context):
        """è®°å½•å›¾åƒå¤„ç†å¤±è´¥"""
        self.error(f"âŒ å›¾åƒå¤„ç†å¤±è´¥: {task_id}",
                  action="image_processing_failed",
                  task_id=task_id,
                  error=error,
                  **context)
    
    def log_model_switch(self, old_model: str, new_model: str, switch_time: float):
        """è®°å½•æ¨¡å‹åˆ‡æ¢"""
        self.info(f"ğŸ”„ æ¨¡å‹åˆ‡æ¢: {old_model} -> {new_model} ({switch_time:.2f}s)",
                 action="model_switch",
                 old_model=old_model,
                 new_model=new_model,
                 switch_time=switch_time)
    
    def log_session_start(self, session_id: str, user_agent: str, ip_address: str):
        """è®°å½•ç”¨æˆ·ä¼šè¯å¼€å§‹"""
        self.info(f"ğŸ‘¤ æ–°ç”¨æˆ·ä¼šè¯: {session_id}",
                 action="session_start",
                 session_id=session_id,
                 user_agent=user_agent,
                 ip_address=ip_address)
    
    def log_session_end(self, session_id: str, duration: float, requests_count: int):
        """è®°å½•ç”¨æˆ·ä¼šè¯ç»“æŸ"""
        self.info(f"ğŸ‘‹ ç”¨æˆ·ä¼šè¯ç»“æŸ: {session_id} (æ—¶é•¿: {duration:.1f}s, è¯·æ±‚: {requests_count})",
                 action="session_end",
                 session_id=session_id,
                 duration=duration,
                 requests_count=requests_count)
    
    def log_api_error(self, error_type: str, error_msg: str, endpoint: str, **context):
        """è®°å½•APIé”™è¯¯"""
        self.error(f"âŒ APIé”™è¯¯: {error_type} - {error_msg}",
                  action="api_error",
                  error_type=error_type,
                  error_message=error_msg,
                  endpoint=endpoint,
                  **context)
    
    def log_performance_warning(self, metric: str, value: float, threshold: float, **context):
        """è®°å½•æ€§èƒ½è­¦å‘Š"""
        self.warning(f"âš ï¸ æ€§èƒ½è­¦å‘Š: {metric} = {value:.2f} (é˜ˆå€¼: {threshold})",
                    action="performance_warning",
                    metric=metric,
                    value=value,
                    threshold=threshold,
                    **context)


# ä¾¿æ·å‡½æ•°ï¼Œç”¨äºè·å–å„ç§æ—¥å¿—å™¨
def get_scheduler_logger() -> SchedulerLogger:
    """è·å–è°ƒåº¦å™¨æ—¥å¿—å™¨"""
    return SchedulerLogger()

def get_worker_logger(node_id: str) -> WorkerLogger:
    """è·å–å·¥ä½œèŠ‚ç‚¹æ—¥å¿—å™¨"""
    return WorkerLogger(node_id)

def get_task_manager_logger() -> TaskManagerLogger:
    """è·å–ä»»åŠ¡ç®¡ç†å™¨æ—¥å¿—å™¨"""
    return TaskManagerLogger()

def get_queue_manager_logger() -> QueueManagerLogger:
    """è·å–é˜Ÿåˆ—ç®¡ç†å™¨æ—¥å¿—å™¨"""
    return QueueManagerLogger()

def get_api_server_logger() -> APIServerLogger:
    """è·å–APIæœåŠ¡å™¨æ—¥å¿—å™¨"""
    return APIServerLogger()

def get_model_manager_logger() -> ModelManagerLogger:
    """è·å–æ¨¡å‹ç®¡ç†å™¨æ—¥å¿—å™¨"""
    return ModelManagerLogger()